{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pylab\n",
    "import pickle\n",
    "import warnings\n",
    "import operator\n",
    "import tldextract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pylab.rcParams['figure.figsize'] = (14.0, 5.0)\n",
    "pylab.rcParams['axes.grid'] = True\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset : 420464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diaryofagameaddict.com</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>espdesign.com.au</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iamagameaddict.com</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalantzis.net</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slightlyoffcenter.net</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url label\n",
       "0  diaryofagameaddict.com   bad\n",
       "1        espdesign.com.au   bad\n",
       "2      iamagameaddict.com   bad\n",
       "3           kalantzis.net   bad\n",
       "4   slightlyoffcenter.net   bad"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', encoding='utf-8')\n",
    "\n",
    "print (\"size of dataset :\", df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    344821\n",
      "1     75643\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.label = df.label.replace(to_replace=\"good\", value=0)\n",
    "df.label = df.label.replace(to_replace=\"bad\", value=1)\n",
    "\n",
    "print (df.label.value_counts())\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix : (420464, 3180519)\n"
     ]
    }
   ],
   "source": [
    "# converting data to vectors\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(3,5))\n",
    "vectorizer.fit(df.url)\n",
    "\n",
    "X =  vectorizer.transform(df.url)\n",
    "print (\"sparse matrix :\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of class : 344821 75643\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #splitting data\n",
    "\n",
    "good = df.label.value_counts()[0]\n",
    "bad = df.label.value_counts()[1]\n",
    "print (\"size of class :\", good, bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 344821, 1: 75643}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgs = LogisticRegression(class_weight={0 : good, 1 : bad})\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad samples : 75643\n",
      "Good samples: 344821\n",
      "Baseline Constant negative: 0.820096\n",
      "------------\n",
      "Accuracy    : 0.987835\n",
      "Precision   : 0.984972\n",
      "Recall      : 0.946071\n",
      "F1-Score    : 0.965129\n",
      "AUC         : 0.997829\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Evaluation #\n",
    "##############\n",
    "\n",
    "predicted = lgs.predict(X_test)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "print (\"Bad samples : %d\" % bad)\n",
    "print (\"Good samples: %d\" % good)\n",
    "print (\"Baseline Constant negative: %.6f\" % (good / (good + bad)))\n",
    "print (\"------------\")\n",
    "print (\"Accuracy    : %f\" % lgs.score(X_test, y_test))  #checking the accuracy\n",
    "print (\"Precision   : %f\" % metrics.precision_score(y_test, predicted))\n",
    "print (\"Recall      : %f\" % metrics.recall_score(y_test, predicted))\n",
    "print (\"F1-Score    : %f\" % metrics.f1_score(y_test, predicted))\n",
    "print (\"AUC         : %f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'url_malicious_model.sav'\n",
    "\n",
    "pickle.dump(lgs, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename1 = 'url_tfidf_model.sav'\n",
    "\n",
    "pickle.dump(vectorizer, open(filename1, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### real rowdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename = 'url_malicious_model.sav'\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename1 = 'url_tfidf_model.sav'\n",
    "\n",
    "loaded_model1 = pickle.load(open(filename1, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 0.04265284538269043\n",
      "[0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "X_real = [\"wikipedia.com\",\n",
    "          \"google.com/search=faizanahmad\",\n",
    "          \"pakistanifacebookforever.com/getpassword.php/\",\n",
    "          \"www.radsport-voggel.de/wp-admin/includes/log.exe\",\n",
    "          \"ahrenhei.without-transfer.ru/nethost.exe\",\n",
    "          \"www.itidea.it/centroesteticosothys/img/_notes/gum.exe\",\n",
    "          \"xn--cgopolygon-wy2e.com/login.php\"]\n",
    "\n",
    "X_real = loaded_model1.transform(X_real)\n",
    "y_real = loaded_model.predict(X_real)\n",
    "\n",
    "t1 = time.time()\n",
    "print (\"cost time :\", t1-t0)\n",
    "print (y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
